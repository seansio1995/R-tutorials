tauhatseminar = (4+14)/piseminar
tauhat3 = (tauhatlarge + tauhatmedium + tauhatseminar)/0.5
tauhat = (tauhat1+tauhat2+tauhat3)/3
varhat = var(c(tauhat1,tauhat2,tauhat3))/3
lcl = tauhat - tcrit(2)*sqrt(varhat)
ucl = tauhat + tcrit(2)*sqrt(varhat)
confint = c(lcl,ucl)
tauhat
confint
pi = (1/3)*(1/26) ## Probability a room in Building 2 is selected.
tauhat1 = 16/pi ## Total estimate for all 3 buildings
pi = (1/3)*(1/22) ## Probability a room in Building 2 is selected.
tauhat2 = 10/pi ## Total estimate for all 3 buildings
pi = (1/3)*(1/26) ## Probability a room in Building 1 is selected.
tauhat3 = 6/pi ## Total estimate for all 3 buildings
tauhat = (tauhat1+tauhat2+tauhat3)/3
varhat = var(c(tauhat1,tauhat2,tauhat3))/3
lcl = tauhat - tcrit(2)*sqrt(varhat)
ucl = tauhat + tcrit(2)*sqrt(varhat)
confint = c(lcl,ucl)
tauhat
confint
pi = (1/3)*(2/22) ## Probability a room in Building 3 is selected.
pi = (1/3)*(1/22) ## Probability a room in Building 2 is selected.
tauhat1 = 16/pi ## Total estimate for all 3 buildings
pi = (1/3)*(1/22) ## Probability a room in Building 2 is selected.
tauhat2 = 10/pi ## Total estimate for all 3 buildings
pi = (1/3)*(1/26) ## Probability a room in Building 1 is selected.
tauhat3 = 6/pi ## Total estimate for all 3 buildings
tauhat = (tauhat1+tauhat2+tauhat3)/3
varhat = var(c(tauhat1,tauhat2,tauhat3))/3
lcl = tauhat - tcrit(2)*sqrt(varhat)
ucl = tauhat + tcrit(2)*sqrt(varhat)
confint = c(lcl,ucl)
tauhat
confint
pi = (1/3)*(2/22) ## Probability a room in Building 3 is selected.
tauhat1 = (8+10)/pi ## Total estimate for all 3 buildings
pi = (1/3)*(2/22) ## Probability a room in Building 2 is selected.
tauhat2 = (6+12)/pi ## Total estimate for all 3 buildings
pi = (1/3)*(2/22) ## Probability a room in Building 3 is selected.
tauhat3 = (8+18)/pi ## Total estimate for all 3 buildings
pi = (1/3)*(2/26) ## Probability a room in Building 1 is selected.
tauhat4 = (14+4)/pi ## Total estimate for all 3 buildings
tauhat = (tauhat1+tauhat2+tauhat3+tauhat4)/4
varhat = var(c(tauhat1,tauhat2,tauhat3,tauhat4))/4
lcl = tauhat - tcrit(3)*sqrt(varhat)
ucl = tauhat + tcrit(3)*sqrt(varhat)
confint = c(lcl,ucl)
tauhat
confint
pilarge = 2/10
tauhatlarge = (10+16)/pilarge
pimedium = 2/8
tauhatmedium = (8+4)/pimedium
piseminar = 2/8
tauhatseminar = (10+8)/piseminar
tauhat1 = (tauhatlarge + tauhatmedium + tauhatseminar)/0.5
pilarge = 2/4
tauhatlarge = (18+16)/pilarge
pimedium = 2/16
tauhatmedium = (8+10)/pimedium
piseminar = 2/2
tauhatseminar = (6+8)/piseminar
tauhat2 = (tauhatlarge + tauhatmedium + tauhatseminar)/0.2
pilarge = 2/10
tauhatlarge = (20+16)/pilarge
pimedium = 2/8
tauhatmedium = (8+14)/pimedium
piseminar = 2/8
tauhatseminar = (4+14)/piseminar
tauhat3 = (tauhatlarge + tauhatmedium + tauhatseminar)/0.5
tauhat = (tauhat1+tauhat2+tauhat3)/3
varhat = var(c(tauhat1,tauhat2,tauhat3))/3
lcl = tauhat - tcrit(2)*sqrt(varhat)
ucl = tauhat + tcrit(2)*sqrt(varhat)
confint = c(lcl,ucl)
tauhat
confint
times <- c(8,9,10,11,12,1,2,3,4,5)
probtimes <- c(0.114942529,
0.091954023,
0.08045977,
0.08045977,
0.103448276,
0.086206897,
0.08045977,
0.091954023,
0.126436782,
0.143678161)
timechosen <- sample(times ,1 , replace = TRUE, prob =  probtimes)
timechosen
lots <- c('C1','E1','E3','S6','T4','Culbreth','Bookstore','Emmet')
problots <- c(0.0453,0.0906,0.0755,0.0604,0.0755,0.1692,0.1208,0.3625)
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
lots <- c('C1','E1','E3','S6','T4','Culbreth','Bookstore','Emmet')
problots <- c(0.0453,0.0906,0.0755,0.0604,0.0755,0.1692,0.1208,0.3625)
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
lots <- c('C1','E1','E3','S6','T4','Culbreth','Bookstore','Emmet')
problots <- c(0.0453,0.0906,0.0755,0.0604,0.0755,0.1692,0.1208,0.3625)
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
timechosen <- sample(times ,1 , replace = TRUE, prob =  probtimes)
timechosen
timechosen <- sample(times ,1 , replace = TRUE, prob =  probtimes)
timechosen
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
summary(mtcars)
summary(log(mtcars))
mean(mtcars$mpg)
cor(mtcars)
cor(log(mtcars))
pairs(iris)
library(lattice)
splom(iris)
head(iris)
mysubset=subset(iris,Species="setosa")
mysubset
head(mysubset)
head(mysubset[-2])
set.seed(2489)
hist(ourdata)
ourdata=rnorm(1000,mean=600,sd=80)
hist(ourdata)
sorted.object<-ifelse(ourdata>700,"yes","no")
table(sorted.object)
?prop.test
prop.test(x=yes,n=1000,alternative = "two.sided")
prop.test(x='yes',n=1000,alternative = "two.sided")
prop.test(x=102,n=1000,alternative = "two.sided")
prop.test(x=102,n=1000,alternative = "greater")
prop.test(x=102,n=1000,alternative = "less")
prop.test(x=102,n=1000,alternative = "less")
prop.test(x=102,n=1000,alternative = "two.sided")
prop.test(x=102,n=1000,alternative = "less")
prop.test(x=102,n=1000,alternative = "greater")
mytest=prop.test(x=102,n=1000,alternative = "two.sided")
names(mytest)
mytest$estimate
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
lotchosen <- sample(lots, 1, replace = FALSE, prob =  problots)
lotchosen
qqnorm(ourdata)
set.seed(2489)
ouruniformdata<-runif(1000)
hist(ouruniformdata)
qqnorm(ouruniformdata)
shapiro.test(ourdata)
shapiro.test(ouruniformdata)
shapiro.test(iris$Sepal.Length)
library(nortest)
install.packages("nortest")
library(nortest)
?ad.test
ad.test(rnorm(100,mean = 5,sd=3))
ad.test(runif(100,min = 2,max = 4))
ad.test(ourdata)
ad.test(ouruniformdata)
library(ggplot2)
head(diamonds)
attach(diamonds)
qqnorm(depth)
hist(depth)
length(depth)
depthsmall<-sample(depth,5000)
shapiro.test(depthsmall)
cvm.test(depth)
pearson.test(depth)
?t.test
t.test(x=ourdata, mu=300,alternative = "less",conf.level = 0.95)
hist(ourdata)
t.test(x=ourdata, mu=300,alternative = "greater",conf.level = 0.95)
t.test(x=ourdata, mu=300,alternative = "two.sided",conf.level = 0.95)
head(mtcars)
attach(mtcars)
boxplot(data=mtcars,wt~am)
t.test(mtcars$wt ~ mtcars$am, alt="two.sided",conf=0.95,mu=0,paired=F,var.equal=F)
library(MASS)
?ships
head(ships)
attach(ships)
boxplot(incidents~period)
t.test(incidents~period)
t.test(incidents[period==60],incidents[period==75])
head(iris)
attach(iris)
is.factor(Species)
levels(Species)
by(Sepal.Length,Species,mean)
oneway.test(Sepal.Length~ Species)
myanova<-aov(Sepal.Length~Species,data=iris)
summary(myanova)
attributes(myanova)
TukeyHSD(myanova)
plot(TukeyHSD(myanova))
coefficients(myanova)
library(car)
levene.test(Sepal.Length,Species,data=iris,center="mean")
leveneTest(Sepal.Length,Species,data=iris,center="mean")
attach(mtcars)
table(am,vs)
barplot(table(am,vs),beside = T)
chisq.test(table(am,vs))
fisher.test(table(am,vs))
rnorm(5,5)
myobject<-data.frame(group=rep(c("a","b","c"),10),numerics=c(rnorm(5,5),6:15,rep(c(1,20,98),5)))
myobject
levels(myobject$group)
library(lattice)
bwplot(data=myobject,numeric~group,panel = panel.violin())
bwplot(data=myobject,numeric~group,panel = panel.violin)
bwplot(data=myobject,numerics~group,panel = panel.violin)
myanova<-aov(data=myobject,numerics~group)
summary(myanova)
TukeyHSD(myan)
TukeyHSD(myanov)
TukeyHSD(myanova)
plot(TukeyHSD(myanova))
coefficients(myanova)
kruskal.test(data=myobject,numerics~groupo)
kruskal.test(data=myobject,numerics~group)
?pairwise.t.test
pairwise.t.test(x=myobject$numerics,g=myobject$group,p.adj="BH")
head(bacteria)
attach(bacteria)
table(y,trt)
table(bacteria$y,trt)
chisq.test(table(bacteria$y,trt))
attach(iris)
plot(Sepal.Length,Sepal.Width)
cor(Sepal.Length,Sepal.Width,method="pearson")
cor(Sepal.Length,Sepal.Width,method="spearman")
cor(Sepal.Length,Sepal.Width,method="kendall")
cov(Sepal.Length,Sepal.Width)
cor.test(Sepal.Length,Sepal.Width,method="pearson")
x=c(rnorm(10),150)
x
m=mean(x)
m
s=sd(x)
s1=m-s*t
s2=m+s*t
s=sd(x)
t=3
s1=m-s*t
s2=m+s*t
y=ifelse(x>s1 & s<s2,0,1)
y
y=ifelse(x>=s1 & s<=s2,0,1)
y
s1
s2
y=ifelse(x>=s1 & x<=s2,0,1)
y
boxplot(x)
boxplot.stats(x)
library(outlier)
install.packages("outliers")
library(outliers)
dixon.test(x)
?grubbs.test
grubbs.test(x,type = 11,two.sided = T)
head(mtcars)
head(cars)
attach(cars)
plot(x=speed,y=dist)
cor(speed,dist)
lm(speed~dist)
summary(lm(speed~dist))
model<-lm(speed~dist)
coefficients(model)
model<-lm(dist~speed)
coefficients(model)
confint(model)
anova(model)
plot(model)
plot(model)
addon=data.frame(speed=45)
predict(model,addon)
head(mtcars)
attach(mtcars)
mymodel<-lm(mtcars$mpg~drat+mt)
mymodel<-lm(mtcars$mpg~drat+wt)
summary(mymodel)
cor(drat,wt)
confint(mymodel)
mymodel2<-lm(mtcars$mpg~drat+wt^2+wt)
summary(mymodel2)
mymodel2<-lm(mtcars$mpg~drat+I(wt^2)+wt)
summary(mymodel2)
anova(mymodel2)
attach(mtcars)
glm(data=mtcars,am~wt+mtcars$mpg+drat,family = "binomial")
mymodel3=glm(data=mtcars,am~wt+mtcars$mpg+drat,family = "binomial")
summary(mymodel3)
mymodel4=glm(data=mtcars,am~wt,family="binomial")
summary(mymodel4)
addon=data.frame(wt=4.5)
predict(mymodel4,addon,type="response")
summary(PlantGrowth)
attach(PlantGrowth)
plot(group,weight)
mysubset=subset(PlantGrowth,group!="ctrl")
mymodel5=glm(data=mysubset,group~weight,family = "binomial")
summary(mymodel5)
addon=data.frame(weight=7.5)
predict(mymodel5,addon,type="response")
attach(mtcars
)
library(lattice)
with(mtcars,xyplot(wt~mtcars$mpg,group=mtcars$cyl,auto.key = 20,pch=20,cex=3))
library(class)
train=cbind(mtcars$mpg,wt)
head(mtcars)
test=c(26,2.2)
knn(train,test,cl=mtcars$cyl,prob = T)
knn(train,test,cl=mtcars$cyl,k=2,prob = T)
knn(train,test,cl=mtcars$cyl,k=2,prob = T)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(ggplot2)
set.seed(123)
head(diamonds)
baggin=randomForest(formula=color~., data=diamonds[1:500,],mtr=9)
plot(bagging)
plot(baggin)
?randomForest
baggin=randomForest(formula=color~., data=diamonds[1:500,],mtr=3)
plot(baggin)
importance(baggin)
varImpPlot(baggin)
baggin2=randomForest(formula=color~., data=diamonds[1:500,],mtr=3)
test=diamonds[501:800,]
predict.baggin2=predict(newdat=test,baggin2,type="class")
predict.baggin=predict(newdata=test,baggin,type="class")
table(predict.baggin,test$color)
table(predict.baggin2,test$color)
sum(diag(table(predict.baggin,test$color)))/300
sum(diag(table(predict.baggin2,test$color)))/300
data<-c(1,2,3,3,2,1,1,3,2)
labeldata=factor(data,labels = c("a","b","c"))
labeldata
x<-array(1:4,dim=c(2,2))
x
x[1,2]
y=matrix(1:8,ncol = 2,nrow=4)
y
type(x)
typeof(x)
.packages(all.available = T)
apple
head(iris)
summary(iris[c("Petal.Length","Petal.width")])
iris[Petal.Length]
iris["Petal.Length"]
iris["Petal.Length","Petal.width"]
iris[c("Petal.Length","Petal.width")]
iris[,c("Petal.Length","Petal.width")]
iris[,c("Petal.Length","Petal.Width")]
summary(iris[,c("Petal.Length","Petal.Width")])
return (x-min(x))/(max(x)-min(x))
normalize<-function(x)
{
return (x-min(x))/(max(x)-min(x))
}
head(iris)
iris[1:4]
normalizeIris<-as.data.frame(lapply(iris[1:4],normalize))
head(normalizeIris)
nrow(normalizeIris)
train<-normalizeIris[1:120,]
test<-normalizeIris[121:150,]
train.labels<-iris[1:120,5]
test.labels<-iris[121:150,5]
library(class)
prediction=knn(train=train,test=test,cl=train.labels,k=10)
table(prediction,test.labels)
sum(diag(table(prediction,test.labels)))/30
prediction2=knn(train=train,test=test,cl=train.labels,k=100)
sum(diag(table(prediction2,test.labels)))/30
getwd()
getwd()
setwd("/Users/tfsp-h/Documents/R/R-tutorials/data/")
iris<-read.csv("iris_data.csv")
head(iris)
library(e1071)
iris<-iris[sample.int(nrow(iris)),]
head(iris)
train<-iris[1:100,]
test<-iris[101:150,]
model<-naiveBayes(Class~.,data=iris)
model<-naiveBayes(Class~.,data=train)
prediction<-predict(model,test)
table(prediction,test[,5])
sum(diag(table(prediction,test[,5])))/sum(table(prediction,test[,5]))
y=runif(20,min=0,max=10)
x=runif(20,min=0,max=10)
plot(x,y)
class<-rep("A",20)
class[x>5]<-"B"
class
plot(x,y,col=ifelse(class="A","red","blue"))
plot(x,y,col=ifelse(class=="A","red","blue"))
plot(x,y,col=ifelse(class=="A","red","blue"),pch=10)
plot(x,y,col=ifelse(class=="A","red","blue"),pch=16)
library(e1071
)
library(e1071)
data<-data.frame(x,y,class)
head(data)
model<-svm(class~x+y,data=data,kernel="linear",cost=0.1)
model
plot(model,data)
predict(model,data.frame(x=1,y=1))
x=runif(40,min=0,max=10)
y=runif(40,min=0,max=10)
class=rep("A",40)
class[x>=2.5 & x<=4.5]="B"
class
data=data.frame(x,y,class)
head(data)
plot(x,y,col=ifelse(class=="A","red","blue"),pch=16)
model<-svm(class~.,data=data,kernel="radial",cost=0.1,gamma=)
model<-svm(class~.,data=data,kernel="radial",cost=0.1,gamma=1)
plot(model,data)
plot(model,data=data)
model<-svm(class~.,data=data,kernel="radial",cost=1,gamma=1)
plot(model,data = data)
tunemodel<-tune(svm,class~.,data=data,kernel="radial",ranges=list(cost=c(0.01,0.1,1,10),gamma=c(0.01,0.1,1,10)))
bestModel<-tunemodel$best.model
bestModel
plot(bestModel,data=data)
predict(bestModel,data.frame(x=1,y=1))
predict(bestModel,data.frame(x=3,y=3))
predict(bestModel,data.frame(x=0,y=1))
predict(bestModel,data.frame(x=2,y=1))
install.packages("tree")
library(tree)
bankData<-read.csv("bank.csv",T,";")
head(bankData)
set.seed(5)
trainSet=sample(nrow(bankData),3000)
trainSet=sample(1:nrow(bankData),3000)
model<-tree(y~.,bankData,subset=trainSet)
summary(model)
plot(model)
text(model,pretty=5)
prediction=predict(model,bankData[-trainSet],type="class")
prediction=predict(model,bankData[-trainSet,],type="class")
with(bankData[-trainSet,],table(prediction,y))
mean(bankData[-trainSet,],table(prediction,y))
ncol(bankData)
mean(bankData[-trainSet,17]==prediction)
library(stats)
y=runif(100,0,10)
x=runif(100,0,10)
plot(x,y)
data=data.frame(x,y)
model=kmeans(data,4,nstart = 15)
model
plot(data,col=model$cluster,pch=16)
model=kmeans(data,6,nstart=15)
model
plot(data,col=model$cluster,pch=16)
clust=hclust(dist(x),method="complete")
clust
plot(clust)
trainingInput<-as.data.frame(runif(50,0,1000))
trainingOutput<-sqrt(trainingInput)
trainData<-cbind(trainingInput,trainingOutput)
colnames(trainData)<-c("input","output")
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
nn<-neuralnet(output~intput,trainData,hidden = 10,threshold = 0.01)
colnames(trainData)<-c("input","output")
nn<-neuralnet(output~intput,trainData,hidden = 10,threshold = 0.01)
head(trainData)
nn<-neuralnet(output~input,trainData,hidden = 10,threshold = 0.01)
head(trainData)
print(nn)
nn<-neuralnet(output~input,trainData,hidden = 10,threshold = 0.01)
print(nn)
nn<-neuralnet(formula=output~input,data=trainData,hidden = 10,threshold = 0.01)
print(nn)
plot(nn)
nn
nn$call
nn$err.fct()
head(trainData)
nn<-neuralnet(formula=output~input,data=trainData,hidden = 10,threshold = 0.01)
creditdata<-read.csv("credit_data.csv",T)
head(creditdata)
trainData=creditdata[1:1500,]
testData=creditdata[1501:2000,]
nn=neuralnet(Default~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal")
nn=neuralnet(default10yr~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal")
print(nn)
plot(nn)
nn=neuralnet(default10yr~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal")
nn=neuralnet(default10yr~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal",rep = 2)
nn=neuralnet(default10yr~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal")
nn=neuralnet(default10yr~LTI+age,trainData,hidden=4,threshold = 0.1,linear.output = F,lifesign = "minimal")
system.time()
Sys.Date()
